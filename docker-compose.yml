version: '3.9'

services:
  predictor-service:
    build: ./predictor-service
    container_name: predictor
    ports:
      - "8000:8000"
    volumes:
      - ./shared:/shared
    environment:
      - MODEL_PATH=/shared/model.pkl

  streamlit-ui:
    build: ./streamlit-ui
    container_name: streamlit
    ports:
      - "8501:8501"
    depends_on:
      - predictor-service
    volumes:
      - ./shared:/shared

  mlflow-server:
    image: ghcr.io/mlflow/mlflow
    container_name: mlflow
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlflow/artifacts
    ports:
      - "5000:5000"
    volumes:
      - ./mlflow/artifacts:/mlflow/artifacts
      - ./mlflow/mlflow.db:/mlflow/mlflow.db

  weave-scope:
    image: weaveworks/scope:1.13.2
    container_name: weave-scope
    privileged: true
    pid: "host"
    network_mode: "host"
    command: "--probe.docker.bridge=docker0"
    ports:
      - "4040:4040"
    restart: always
