version: '3.9'

services:
  predictor-service:
    build: ./predictor-service
    container_name: predictor
    ports:
      - "8000:8000"
    volumes:
      - ./shared:/shared
    environment:
      - MODEL_PATH=/shared/model.pkl

  streamlit-ui:
    build: ./streamlit-ui
    container_name: streamlit
    ports:
      - "8501:8501"
    depends_on:
      - predictor-service
    volumes:
      - ./shared:/shared

  mlflow-server:
    image: ghcr.io/mlflow/mlflow
    container_name: mlflow
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./mlruns:/mlflow/mlruns

  weave-scope:
    image: weaveworks/scope:1.13.2
    container_name: weave-scope
    privileged: true
    pid: "host"
    network_mode: "host"
    command: "--probe.docker.bridge=docker0"
    ports:
      - "4040:4040"
    restart: always
